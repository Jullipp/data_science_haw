---
title: "R Notebook"
output: html_notebook
---
## Notebook zu Session 4

# Libraries und Daten
```{r}
library(tidyverse)
library(e1071)
library(caret)
library(pROC)
library(rpart)
library(rpart.plot)
```

```{r}
titanic <- read_delim("titanic.csv", ";", 
    escape_double = FALSE, trim_ws = TRUE)
```

# Class Imbalance Check

```{r}
titanic %>%
  group_by(survived) %>%
  summarize(n = n())
```

# SVM

```{r}
(titanic.df <- titanic %>%
  select(survived,pclass,sex,age,sibsp,parch) %>%
   mutate(survived = as.factor(survived)))
```

```{r}
titanic.df <- titanic.df %>%
  mutate(age = as.numeric(str_replace(age,",","."),
         sex = ifelse(sex == "female", 1, 0))) %>%
  na.omit(titanic.df)
```

```{r}
set.seed(393)
inTrain <- createDataPartition(
  y = titanic.df$survived,
  p = .8,
  list = FALSE)
training <- titanic.df[ inTrain,]
testing  <- titanic.df[-inTrain,]
```

```{r}
model.svm <- svm(formula = survived ~ ., data = training, probability=TRUE)
summary(model.svm)
pred <- predict(model.svm, testing[,-1], probability = TRUE)
```

```{r}
(test.results <- cbind(pred, testing))
```
```{r}
head(attr(pred, "probabilities"))
```

```{r}
confusionMatrix(pred,testing$survived)
```


```{r}
pROC_obj <- roc(as.numeric(test.results$survived), as.numeric(test.results$pred),
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
```


# Naive Bayes

```{r}
my_training <- training %>%
  mutate(survived = as.factor(survived))%>%
  mutate(sex = as.factor(sex))%>%
  mutate(pclass = as.factor(pclass)) %>%
  mutate(sibsp = as.factor(sibsp)) %>%
  mutate(parch = as.factor(parch)) %>%
  mutate(age = as.factor(ifelse(age < 16, "child", "adult")))
model <- naiveBayes(survived ~ ., data = my_training)
model
```

```{r}
my_testing <- testing %>%
  mutate(sex = as.factor(sex)) %>%
  mutate(pclass = as.factor(pclass))%>%
  mutate(age = as.factor(ifelse(age < 16, "child", "adult")))%>%
  mutate(sibsp = as.factor(sibsp)) %>%
  mutate(parch = as.factor(parch))
pred <- predict(model, my_testing)
table(pred, my_testing$survived)
```


```{r}
(test.results <- cbind(pred, my_testing))
```

```{r}
test.results_nb <- test.results %>%
  mutate(pred = as.numeric(pred))
pROC_obj_nb <- roc(as.numeric(as.factor(test.results_nb$survived)), test.results_nb$pred,
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)

```
# Decision Tree

```{r}
tree<- rpart(survived~., data = training, method = 'class')
rpart.plot(tree)
```
```{r}
dt_results <- predict(tree, testing[,-1], type = 'prob')
head(model.results.dt <- cbind(testing,dt_results),500)
```
```{r}
table(test.results$pred, testing$survived)
```


```{r}
pROC_obj_df <- roc(model.results.dt$survived,model.results.dt$`1`,
            smoothed = TRUE,
            ci=TRUE, ci.alpha=0.9, stratified=FALSE,
            plot=TRUE, auc.polygon=TRUE, max.auc.polygon=TRUE, grid=TRUE,
            print.auc=TRUE, show.thres=TRUE)
```

# Was sind die Unterschiede in der Performance der Algorithmen und wie lassen sie sich erklären?
Der Descision Tree hat eine Performance von 0.87. Der SVM hat eine Performance von 0.852. Der Naive Bayes hat eine Performance von 0.802.

Die hohe Performance des SVM-Algorithmuses kommt vermutlich daher, dass die Datenpunkte, durch die die Support-Vektoren gehen, weit voneinander getrennt sind. Somit kann der Algorithmus leicter Entscheidungen treffen, da die Trennung zwischen dem Tariningsdatensatz und dem Testdatensatz eindeutiger ist.

Der Naive Bayes Algorithmus hat am schlechtesten abgeschnitten, was vielleicht daran liegt, dass der Naive Bayes Algorithmus davon ausgeht, dass die Variabeln nicht miteinander zu tun haben. Allerdings haben die Variabeln siblsp und parch doch etwas miteinander zu tun, da siblsp zum Beispiel aussagt, wie viele Geschwister die Person auf dem Schiff hat und die Variable parch gibt darüber Auskunft, wie viele Kinder diese Person auf dem Schiff hat. Wenn eine Person 3 Geschwister auf dem Schiff hat, dann haben die Eltern dort wahrscheinlich 4 Kinder unter parch stehen. Dieser Zusammenhang könnte eine Erklärung für die niedrige Performance sein. Update: Ein Entfernen der Variabel parch aus den Berechnungen sorgt NICHT für eine Änderung in der Performance.  

Beim Descicion Tree besteht die Gefahr des Overfittings, was ich bei diesem Beispiel nicht vermute, da eine sehr große Ähnlichkeit zwischen dem Trainings- und Testdatensatz die Vorraussetzung dafür wäre. Dies würde im Konflikt mit meiner oben erstellten Theorie, dass die Support-Vektoren beim SVM-Algorithmus aufgrund einer klaren Trennung der beiden Datensätze weit voneinander entfernt sind, stehen. Ansonsten wäre eine mögliche Erklärung für den hohen Performance Wert, dass beim DT die Features für den Testdatensatz selbst gewählt werden. Das halte ich aber für unwahrscheinlich, da der DT im Vergleich mit den anderen Algorithmen nur die Variable parch nicht beachtet. Bei meinem Versuch bei NB, wo ich parch ebenfalls rausgenommen habe, hat das zu keiner Änderung, geschweige den Steigerung beim Performane Wert geführt.  
